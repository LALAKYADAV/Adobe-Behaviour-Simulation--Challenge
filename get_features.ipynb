{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**How to run?**\n",
        "\n",
        "\n",
        "1.   Run the first 2 cells as they are\n",
        "2.   Change the \"file_path\" in cell 3 to the desired file path\n",
        "\n"
      ],
      "metadata": {
        "id": "rtLXQlLdWx0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import vision_transformer\n",
        "from torchvision.models.video import r3d_18\n",
        "import imageio\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def load_pretrained_3d_cnn():\n",
        "    # Load pre-trained 3D CNN model (e.g., ResNet3D)\n",
        "    model = r3d_18(pretrained=True)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# Load the Vision Transformer model\n",
        "def load_vit_model():\n",
        "    model = vision_transformer.vit_b_16(pretrained=True)\n",
        "    model.eval()\n",
        "    return model"
      ],
      "metadata": {
        "id": "8iq7n75aSPCm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to extract features using the Vision Transformer\n",
        "def extract_features_with_transformer(image_path, model):\n",
        "    image = Image.open(image_path).convert('RGB')  # Ensure the image is treated as RGB\n",
        "    image = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "    ])(image).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Use the standard forward method\n",
        "        features = model(image)\n",
        "\n",
        "    return features.squeeze().numpy()\n",
        "\n",
        "\n",
        "\n",
        "def extract_features_with_3d_cnn(video_path, model, num_frames_to_select=120):\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        # Ensure that num_frames_to_select does not exceed the total number of frames\n",
        "        num_frames_to_select = min(num_frames_to_select, total_frames)\n",
        "\n",
        "        # Select frames\n",
        "        selected_frames = np.linspace(0, total_frames - 1, num_frames_to_select, dtype=int)\n",
        "\n",
        "        features_list = []\n",
        "        for frame_idx in selected_frames:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Resize each frame to match the input size of the 3D CNN model\n",
        "            frame_resized = cv2.resize(frame, (112, 112))\n",
        "\n",
        "            # Convert frame to RGB format (assuming it's in BGR)\n",
        "            frame_resized_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Convert frame to tensor\n",
        "            transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "            ])\n",
        "            frame_tensor = transform(frame_resized_rgb).unsqueeze(0)\n",
        "\n",
        "            # Extend frame tensor along the temporal dimension\n",
        "            frame_tensor_3d = frame_tensor.repeat(1, 3, 1, 1, 1)  # Repeat channels to match 3D CNN input\n",
        "\n",
        "            # Extract features from the 3D CNN model for each frame\n",
        "            with torch.no_grad():\n",
        "                features_frame = model(frame_tensor_3d)\n",
        "\n",
        "            features_list.append(features_frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if not features_list:\n",
        "            print(\"No frames found in the video.\")\n",
        "            return None\n",
        "\n",
        "        # Aggregate features from all frames\n",
        "        features_tensor = torch.stack(features_list)\n",
        "        aggregated_features = features_tensor.mean(dim=0)\n",
        "        return aggregated_features.squeeze().numpy()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading video frames: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Load the 3D CNN model outside the loop\n",
        "model_3d_cnn = load_pretrained_3d_cnn()\n",
        "\n",
        "model_vit = load_vit_model()\n",
        "\n",
        "\n",
        "def normalize_array(input_array):\n",
        "    mean = np.mean(input_array)\n",
        "    std = np.std(input_array)\n",
        "    normalized_array = (input_array - mean) / std\n",
        "    return normalized_array\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tmO3br6wNc-",
        "outputId": "29ef2701-2b53-4b82-bded-3218c1479b6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=R3D_18_Weights.KINETICS400_V1`. You can also use `weights=R3D_18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:05<00:00, 59.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def extract_features_from_file(file_path):\n",
        "    _, file_extension = os.path.splitext(file_path)\n",
        "\n",
        "    if file_extension.lower() in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:\n",
        "        # Image file\n",
        "        return extract_features_with_transformer(file_path, model_vit)\n",
        "    elif file_extension.lower() in ['.mp4', '.avi', '.mov', '.mkv', 'webm']:\n",
        "        # Video file\n",
        "        return extract_features_with_3d_cnn(file_path, model_3d_cnn, num_frames_to_select=120)\n",
        "    elif file_extension.lower() in ['.gif']:\n",
        "        # GIF file\n",
        "        return extract_features_with_transformer(file_path, model_vit)\n",
        "    else:\n",
        "        print(f\"Unsupported file type: {file_extension}\")\n",
        "        return None\n",
        "\n",
        "# Example usage:\n",
        "file_path = '/content/cat-video.mp4'\n",
        "\n",
        "features = extract_features_from_file(file_path)\n",
        "\n",
        "# Haha, totally unnecessary\n",
        "features = normalize_array(features)\n",
        "\n",
        "if features is not None:\n",
        "    print(\"Features:\")\n",
        "    print(features, features.shape)\n",
        "else:\n",
        "    print(\"Error extracting features.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXzCBKwuLzNO",
        "outputId": "2c453b4b-3921-4871-d0a8-342a40a0bf8c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:\n",
            "[ 8.01601231e-01 -1.60894185e-01  8.31473351e-01 -4.52724360e-02\n",
            " -2.88302839e-01  8.96757543e-01  3.48300189e-01 -1.02607048e+00\n",
            " -4.92886364e-01 -2.58406550e-01  2.57356435e-01  6.91429913e-01\n",
            " -1.23900902e+00  1.21721423e+00 -8.08469236e-01 -1.45828581e+00\n",
            "  1.52600813e+00  6.08039677e-01 -4.88237977e-01  5.91618657e-01\n",
            "  1.36491835e+00  5.25291637e-02 -3.73319805e-01 -2.66194582e-01\n",
            "  1.15501627e-01 -1.49223804e+00  1.75424084e-01 -1.24165580e-01\n",
            " -1.24127519e+00 -1.69156015e-01  4.61939633e-01  1.74247757e-01\n",
            "  1.79955649e+00 -7.40244627e-01  1.67008817e+00  3.33798349e-01\n",
            "  1.77910888e+00  1.00968170e+00 -3.56542438e-01 -2.98465520e-01\n",
            " -1.26642513e+00 -3.93640429e-01 -3.79487008e-01 -1.18483305e-01\n",
            " -2.97408193e-01  9.42761362e-01  9.50235605e-01 -3.08271796e-01\n",
            "  1.56880841e-01 -6.14339173e-01 -9.58047032e-01 -1.47849226e+00\n",
            "  3.69023204e-01  5.66570222e-01 -1.23563230e+00  8.68745685e-01\n",
            "  2.31979012e+00  1.07317019e+00 -3.37347865e-01 -3.55733365e-01\n",
            " -8.69588256e-01  4.60250348e-01 -1.31985807e+00  1.29952848e+00\n",
            " -9.07361686e-01  2.04046696e-01  1.24705803e+00  1.41669106e+00\n",
            "  1.21260500e+00 -2.46662810e-01 -1.50264156e+00 -1.07363093e+00\n",
            " -5.99157274e-01 -3.04964930e-01 -2.44239584e-01 -1.32306242e+00\n",
            "  2.19454259e-01  1.56945968e+00 -1.04785573e+00  8.27290297e-01\n",
            "  9.38555002e-01  1.41597199e+00  9.64961648e-01  5.06311297e-01\n",
            "  3.32838029e-01  5.04948258e-01  2.48970404e-01 -1.14612889e+00\n",
            "  7.53989592e-02 -8.00430238e-01  1.37143624e+00 -3.69884998e-01\n",
            " -1.33869183e+00  7.62983918e-01  1.32472551e+00 -1.31820440e+00\n",
            "  6.41138136e-01  2.02866904e-02  1.16052222e+00 -8.53832811e-02\n",
            "  2.46454015e-01  8.22660863e-01 -6.55583084e-01 -1.65781593e+00\n",
            " -6.38129711e-01  4.88216013e-01 -2.18747482e-01 -5.63512743e-01\n",
            "  5.88801265e-01 -5.68951786e-01  6.00417912e-01  3.54182482e-01\n",
            "  4.16271269e-01 -1.06733894e+00 -8.28609526e-01  1.15221441e-01\n",
            " -1.81850582e-01 -6.07888460e-01 -8.99117649e-01 -8.19479376e-02\n",
            " -1.03356504e+00 -3.98613453e-01  2.63252497e-01 -1.86985940e-01\n",
            " -1.29814017e+00  9.08071518e-01 -1.48621917e+00  1.35153639e+00\n",
            "  1.14341521e+00 -3.59694302e-01 -1.37659621e+00  1.07043004e+00\n",
            " -3.01527470e-01 -3.53133768e-01 -7.82866597e-01 -1.45635223e+00\n",
            " -1.00639570e+00  3.45069468e-01  2.47775364e+00  1.18285668e+00\n",
            " -1.00312555e+00 -9.53195870e-01 -2.12513417e-01 -7.69716740e-01\n",
            " -5.58986127e-01  1.76132691e+00  1.31357253e+00  2.57507634e+00\n",
            "  9.33337212e-01  7.29838669e-01  1.72921550e+00 -3.80510062e-01\n",
            "  9.02854443e-01 -1.03723919e+00 -1.15632391e+00  1.08429265e+00\n",
            " -3.68689686e-01 -1.87487757e+00  8.99249196e-01  2.78803736e-01\n",
            " -1.67065606e-01  7.51874670e-02  8.20805132e-01 -4.71115112e-02\n",
            "  4.06826548e-02  5.43042839e-01 -2.82999396e-01 -1.32421231e+00\n",
            " -5.23226023e-01 -3.09325039e-01  6.40441254e-02 -2.80285984e-01\n",
            " -1.84347540e-01  8.65800440e-01 -8.30175817e-01 -1.29321349e+00\n",
            "  7.96709657e-01 -6.38606608e-01  2.46710825e+00  7.36389160e-01\n",
            "  9.19940114e-01  9.88169253e-01 -4.34400767e-01 -8.70799005e-01\n",
            " -7.77309299e-01 -6.69020653e-01  1.28060639e+00  2.30466295e-03\n",
            " -9.29101825e-01  8.28111172e-01  1.01393676e+00 -8.62344578e-02\n",
            " -1.26652622e+00 -2.82591134e-01  7.20457807e-02 -9.36799407e-01\n",
            "  1.63596523e+00  1.08747113e+00 -5.91541290e-01 -1.17793214e+00\n",
            " -5.64101517e-01 -7.70513892e-01 -1.10538828e+00  6.59249723e-01\n",
            " -9.11985278e-01 -2.07176399e+00 -1.47945571e+00  1.53022885e+00\n",
            " -9.23165858e-01 -2.28360236e-01 -2.48986006e-01 -8.43753219e-02\n",
            "  1.53385675e+00  3.19159341e+00 -8.57266605e-01  1.02934919e-01\n",
            " -6.80873215e-01 -3.99740964e-01 -9.71402764e-01 -2.95749307e-01\n",
            "  4.41957772e-01  9.58446041e-02 -2.17708424e-01 -2.81101584e-01\n",
            "  1.65632904e+00 -7.96853244e-01 -1.09637022e+00 -1.16239989e+00\n",
            " -7.67662466e-01  1.07521832e+00 -1.17873394e+00 -1.03350675e+00\n",
            " -2.89281189e-01  1.17645049e+00 -5.18457413e-01 -2.90490896e-01\n",
            " -8.93727958e-01 -1.48124278e+00  8.19005072e-01 -2.55493850e-01\n",
            "  8.72273624e-01 -4.45097357e-01  6.31579280e-01 -5.19150794e-02\n",
            " -4.06292498e-01 -5.47242820e-01 -6.62969947e-01 -4.55888450e-01\n",
            " -3.42614979e-01 -4.35735397e-02 -1.30068791e+00  6.41225159e-01\n",
            "  3.36732000e-01 -6.08555734e-01 -2.42975259e+00  1.36236131e+00\n",
            "  5.36594748e-01 -5.60092509e-01  2.12140247e-01  6.55900240e-01\n",
            "  3.16220790e-01 -9.45760906e-01 -7.03397498e-04  1.03027284e+00\n",
            " -9.09624696e-02  4.36682731e-01  3.80444318e-01 -7.61229515e-01\n",
            " -7.72564173e-01  5.67024410e-01  1.66977441e+00 -9.98906255e-01\n",
            " -2.85273820e-01  4.31516260e-01 -2.25191641e+00 -8.22436154e-01\n",
            "  3.41317117e-01 -1.52594519e+00  1.51755702e+00  1.88267425e-01\n",
            " -1.54599714e+00 -9.78790641e-01 -2.97161728e-01 -6.93002999e-01\n",
            " -7.39516914e-01 -1.23267531e+00 -1.45769751e+00 -1.70783782e+00\n",
            "  8.11944723e-01  8.74234438e-01 -6.52907014e-01  1.22057962e+00\n",
            "  2.14794445e+00 -3.27897310e-01  3.01584315e+00  3.63880134e+00\n",
            " -8.53158712e-01 -1.72539282e+00 -6.47162080e-01  3.00359130e-01\n",
            " -5.89282252e-02  8.66953850e-01  3.73256236e-01 -3.23011190e-01\n",
            " -1.71598852e+00  2.21111059e+00  6.52719796e-01 -7.32886791e-01\n",
            " -6.15891755e-01 -1.00283313e+00 -1.62300706e+00  2.21607406e-02\n",
            " -2.01790690e+00  6.10022783e-01  9.89784122e-01  9.23565507e-01\n",
            "  1.09345555e+00  7.95106828e-01  3.16561580e-01  9.57071543e-01\n",
            " -5.65846622e-01 -1.64812553e+00 -2.76155680e-01 -4.64729548e-01\n",
            " -3.83125365e-01  3.12428641e+00 -7.82439709e-01  2.65948713e-01\n",
            " -8.62193704e-01 -4.78269756e-01 -4.52734411e-01  7.74069846e-01\n",
            " -1.15775364e-02  3.96624595e-01  5.78700185e-01 -6.69881463e-01\n",
            " -4.85653609e-01 -1.30846810e+00 -8.68129671e-01 -9.04133558e-01\n",
            " -9.30907011e-01 -2.61644721e-01  4.88744855e-01  4.53433901e-01\n",
            "  2.45440453e-01  2.69638747e-01  1.43589675e+00  1.39821553e+00\n",
            " -2.83812165e-01  1.18560994e+00 -2.66300817e-03 -2.90916283e-02\n",
            " -5.55761158e-01 -1.30000472e+00  1.50904670e-01 -1.05872393e+00\n",
            "  2.57159853e+00  2.48695188e-03 -6.39637649e-01  3.27653885e-01\n",
            " -9.13235024e-02  7.43855178e-01 -1.39596796e+00  2.20700121e+00\n",
            "  1.74417734e+00  1.68895066e+00  4.79967445e-01 -5.27011335e-01\n",
            "  1.67580462e+00  1.56070769e+00  7.36763954e-01 -3.33730906e-01\n",
            "  2.48404890e-01 -9.38404799e-02 -1.09419143e+00 -1.58413351e+00\n",
            " -6.69328630e-01 -4.09195185e-01  7.15259016e-02 -2.38711566e-01\n",
            " -6.34966671e-01  2.01925921e+00  1.03441067e-01 -5.88788748e-01\n",
            " -4.74925846e-01 -1.80814910e+00 -4.33897585e-01  2.57096022e-01\n",
            " -1.19602166e-01 -1.94278732e-02  9.93848920e-01  4.65961307e-01\n",
            "  5.32169044e-01 -3.90907437e-01  1.12466820e-01  1.23503971e+00\n",
            "  5.30992210e-01  1.69776571e+00  2.19646305e-01 -1.68174791e+00] (400,)\n"
          ]
        }
      ]
    }
  ]
}